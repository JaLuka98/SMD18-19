{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 21 (Dritte Aufgabe auf dem Blatt) - Lineare Klassifikation mit Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indikator(i,j):\n",
    "    if i == j:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Shit brauche ich nicht, das wird im Code so schon gemacht. Kann man aber wieder implementieren...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X, W, b):\n",
    "    '''Gives back a matrix. q[i,j] is the confidence that point X[i] belongs to the j-th class.'''\n",
    "    scores = np.matmul(W, X) + b # quasi eine f-Matrix\n",
    "    nenner = scores.sum(axis=0) # Summiere bitte entlang der Spalten\n",
    "    q = scores/nenner\n",
    "    return q\n",
    "\n",
    "\n",
    "def getPredictions(q):\n",
    "    '''Returns the predicted labels with q from softmax'''\n",
    "    return np.argmax(q,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class net:    \n",
    "    def __init__(self):\n",
    "        np.random.seed(3)\n",
    "        self.W = np.random.randn(2,2)\n",
    "        self.W = np.array([[0.1,0.1],[0.2,0.2]])\n",
    "        self.b = np.zeros((2,1))\n",
    "        \n",
    "    def train(self, X, labels, stepsize, epochs):\n",
    "        m = X.shape[1]\n",
    "        for i in range(epochs):\n",
    "            scores = np.dot(self.W, X) + self.b \n",
    "            exp_scores = np.exp(scores)\n",
    "            probs = exp_scores / np.sum(exp_scores, axis=0, keepdims=True) # [N x K]\n",
    "            #if i%10 == 0:\n",
    "            print(probs)\n",
    "            # compute the loss: average cross-entropy loss and regularization\n",
    "            correct_logprobs = -np.log(probs)\n",
    "            loss = np.sum(correct_logprobs)/m\n",
    "            # compute the gradient on scores\n",
    "            dscores = probs\n",
    "            for column in range(0,m):\n",
    "                if labels[column] == 0:\n",
    "                    dscores[0,column] -= 1\n",
    "                else:\n",
    "                    dscores[1,column] -= 1\n",
    "            dscores /= m\n",
    "            # backpropate the gradient to the parameters (W,b)\n",
    "            dW = np.dot(dscores, X.T)\n",
    "            print('dW', dW)\n",
    "            db = np.sum(dscores, axis=1, keepdims=True)\n",
    "            # perform a parameter update\n",
    "            self.W += -h * dW\n",
    "            self.b += -h * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.67209047e-01   9.99374539e-01   9.99814476e-01   9.99898972e-01]\n",
      " [  3.27909526e-02   6.25461221e-04   1.85524389e-04   1.01028162e-04]]\n",
      "[[ 0.95126073  0.97948667  0.1736252   0.01374552]\n",
      " [ 0.04873927  0.02051333  0.8263748   0.98625448]]\n",
      "[[ 0.96110541  0.98445257  0.18547313  0.01347116]\n",
      " [ 0.03889459  0.01554743  0.81452687  0.98652884]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "\n",
    "testnet = net()\n",
    "testnet.train(X, labels, stepsize = 0.05, epochs = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36253684  0.56658894  0.69309117 ...,  0.23672183  0.15478183\n",
      "   0.17479443]\n",
      " [ 0.63746316  0.43341106  0.30690883 ...,  0.76327817  0.84521817\n",
      "   0.82520557]]\n",
      "dW [[ 0.45002803 -0.70129593]\n",
      " [-0.45002803  0.70129593]]\n",
      "[[ 0.92149541  0.95594488  0.97021008 ...,  0.20366728  0.3084269\n",
      "   0.24623718]\n",
      " [ 0.07850459  0.04405512  0.02978992 ...,  0.79633272  0.6915731\n",
      "   0.75376282]]\n",
      "dW [[ 0.43211727  0.05094731]\n",
      " [-0.43211727 -0.05094731]]\n",
      "[[ 0.8553663   0.99077081  0.99861877 ...,  0.00790851  0.00445642\n",
      "   0.00423813]\n",
      " [ 0.1446337   0.00922919  0.00138123 ...,  0.99209149  0.99554358\n",
      "   0.99576187]]\n",
      "dW [[-0.41247422 -0.65894442]\n",
      " [ 0.41247422  0.65894442]]\n",
      "[[ 0.99534337  0.98169281  0.95596251 ...,  0.75979391  0.97031405\n",
      "   0.93073864]\n",
      " [ 0.00465663  0.01830719  0.04403749 ...,  0.24020609  0.02968595\n",
      "   0.06926136]]\n",
      "dW [[ 2.0458566   1.14024785]\n",
      " [-2.0458566  -1.14024785]]\n",
      "[[  1.01542100e-01   9.99967923e-01   9.99999991e-01 ...,   4.65559273e-09\n",
      "    1.51728598e-11   5.11073400e-11]\n",
      " [  8.98457900e-01   3.20766559e-05   8.51600576e-09 ...,   9.99999995e-01\n",
      "    1.00000000e+00   1.00000000e+00]]\n",
      "dW [[-0.73547762 -1.25286111]\n",
      " [ 0.73547762  1.25286111]]\n",
      "[[  9.90432919e-01   9.99905301e-01   9.99995491e-01 ...,   2.95597464e-04\n",
      "    2.19124926e-04   1.53534821e-04]\n",
      " [  9.56708065e-03   9.46994720e-05   4.50925188e-06 ...,   9.99704403e-01\n",
      "    9.99780875e-01   9.99846465e-01]]\n",
      "dW [[-0.37662295 -0.45323099]\n",
      " [ 0.37662295  0.45323099]]\n",
      "[[  9.99241757e-01   9.99777466e-01   9.99901265e-01 ...,   3.45145543e-02\n",
      "    1.95185195e-01   8.35833718e-02]\n",
      " [  7.58242839e-04   2.22533614e-04   9.87354282e-05 ...,   9.65485446e-01\n",
      "    8.04814805e-01   9.16416628e-01]]\n",
      "dW [[ 0.14504284  0.09269091]\n",
      " [-0.14504284 -0.09269091]]\n",
      "[[  9.98591608e-01   9.99851881e-01   9.99966527e-01 ...,   7.74504700e-03\n",
      "    2.80467004e-02   1.25818263e-02]\n",
      " [  1.40839174e-03   1.48118633e-04   3.34727394e-05 ...,   9.92254953e-01\n",
      "    9.71953300e-01   9.87418174e-01]]\n",
      "dW [[-0.03518364 -0.05536967]\n",
      " [ 0.03518364  0.05536967]]\n",
      "[[  9.98932714e-01   9.99838797e-01   9.99953785e-01 ...,   1.24867027e-02\n",
      "    5.64061064e-02   2.40042184e-02]\n",
      " [  1.06728603e-03   1.61202593e-04   4.62154557e-05 ...,   9.87513297e-01\n",
      "    9.43593894e-01   9.75995782e-01]]\n",
      "dW [[ 0.01868752 -0.00643292]\n",
      " [-0.01868752  0.00643292]]\n",
      "[[  9.98919104e-01   9.99847632e-01   9.99958257e-01 ...,   1.09085198e-02\n",
      "    4.84789989e-02   2.05908905e-02]\n",
      " [  1.08089624e-03   1.52367647e-04   4.17429636e-05 ...,   9.89091480e-01\n",
      "    9.51521001e-01   9.79409110e-01]]\n",
      "dW [[ 0.0061851  -0.01657933]\n",
      " [-0.0061851   0.01657933]]\n",
      "[[  9.98971137e-01   9.99851022e-01   9.99958461e-01 ...,   1.09319803e-02\n",
      "    5.02563905e-02   2.10989753e-02]\n",
      " [  1.02886303e-03   1.48978335e-04   4.15394275e-05 ...,   9.89068020e-01\n",
      "    9.49743610e-01   9.78901025e-01]]\n",
      "dW [[ 0.00864517 -0.01376618]\n",
      " [-0.00864517  0.01376618]]\n"
     ]
    }
   ],
   "source": [
    "df_P_0 = pd.read_hdf('populationen.hdf5', key = 'P_0')\n",
    "P_0 = df_P_0.values\n",
    "df_P_1 = pd.read_hdf('populationen.hdf5', key = 'P_1')\n",
    "P_1 = df_P_1.values\n",
    "P = np.concatenate((P_0,P_1))\n",
    "P = np.transpose(P)\n",
    "labels = np.concatenate((np.zeros(P_0.shape[0]),np.ones(P_1.shape[0])))\n",
    "\n",
    "testnet = net()\n",
    "testnet.train(P, labels, stepsize = 0.05, epochs = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
