{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 21 (Dritte Aufgabe auf dem Blatt) - Lineare Klassifikation mit Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indikator(i,j):\n",
    "    if i == j:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X, W, b):\n",
    "    '''Gives back a matrix. q[i,j] is the confidence that point X[i] belongs to the j-th class.'''\n",
    "    scores = np.matmul(W, X) + b # quasi eine f-Matrix\n",
    "    nenner = scores.sum(axis=0) # Summiere bitte entlang der Spalten\n",
    "    q = scores/nenner\n",
    "    return q\n",
    "\n",
    "\n",
    "def getPredictions(q):\n",
    "    '''Returns the predicted labels with q from softmax'''\n",
    "    return np.argmax(q,axis=0)\n",
    "\n",
    "def learn(X, W, b, h, epochs):\n",
    "    m = X.shape[0] # amount of data points\n",
    "    for i in range(0,epochs):\n",
    "        q = softmax(X, W, b)\n",
    "        predictions = getPredictions(q)\n",
    "        diff = labels - predictions # the error in predicting the labels\n",
    "        summeFuer0 = np.zeros(2)\n",
    "        summeFuer1 = np.zeros(2)\n",
    "        for i in range(0, X.shape[1]):\n",
    "            if labels[i] == 0 and predictions[i] == 1:\n",
    "                summeFuer0 += X[:,i]\n",
    "                summeFuer1 -= X[:,i]\n",
    "            elif labels[i] == 1 and predictions[i] == 0:\n",
    "                summeFuer0 -= X[:,i]\n",
    "                summeFuer1 += X[:,i]\n",
    "        W[0] = W[0] - h/m * summeFuer0\n",
    "        W[1] = W[1] - h/m * summeFuer0\n",
    "        b = b - h/m * sum(diff)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5488135   0.71518937]\n",
      " [ 0.60276338  0.54488318]]\n",
      "[[ 0.4236548 ]\n",
      " [ 0.64589411]]\n"
     ]
    }
   ],
   "source": [
    "df_P_0 = pd.read_hdf('populationen.hdf5', key = 'P_0')\n",
    "P_0 = df_P_0.values\n",
    "df_P_1 = pd.read_hdf('populationen.hdf5', key = 'P_1')\n",
    "P_1 = df_P_1.values\n",
    "P = np.concatenate((P_0,P_1))\n",
    "P = np.transpose(P)\n",
    "labels = np.concatenate((np.zeros(P_0.shape[0]),np.ones(P_1.shape[0])))\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.rand(2,2)\n",
    "b = np.random.rand(2,1)\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 1 0]\n",
      " [0 1 3 4]]\n",
      "[ 0.  0.  1.  1.]\n",
      "[[ 28.48061361 -27.21661074]\n",
      " [  6.32624636  -5.1785998 ]]\n",
      "[[ 28.43670409 -27.17270122]\n",
      " [  5.67840914  -4.53076258]]\n",
      "[[ 28.38149096 -27.11748809]\n",
      " [  5.01355371  -3.86590715]]\n",
      "[[ 28.31423388 -27.05023101]\n",
      " [  4.33046438  -3.18281782]]\n",
      "[[ 28.23409092 -26.97008805]\n",
      " [  3.62775081  -2.48010425]]\n",
      "[[ 28.14009803 -26.87609516]\n",
      " [  2.90381109  -1.75616453]]\n",
      "[[ 28.03114268 -26.76713981]\n",
      " [  2.15678411  -1.00913755]]\n",
      "[[ 27.90592972 -26.64192685]\n",
      " [  1.38448729  -0.23684073]]\n",
      "[[ 27.76293642 -26.49893355]\n",
      " [  0.58433353   0.56331303]]\n",
      "[[ 27.600352   -26.33634913]\n",
      " [ -0.24678139   1.39442795]]\n",
      "[[ 27.41599475 -26.15199188]\n",
      " [ -1.11263521   2.26028176]]\n",
      "[[ 27.20719563 -25.94319276]\n",
      " [ -2.01790174   3.1655483 ]]\n",
      "[[ 26.97062994 -25.70662707]\n",
      " [ -2.9684776    4.11612416]]\n",
      "[[ 26.70206584 -25.43806297]\n",
      " [ -3.97197869   5.11962525]]\n",
      "[[ 26.39597305 -25.13197018]\n",
      " [ -5.03852809   6.18617465]]\n",
      "[[ 26.04488314 -24.78088027]\n",
      " [ -6.18207366   7.32972022]]\n",
      "[[ 25.63827699 -24.37427412]\n",
      " [ -7.4227427    8.57038926]]\n",
      "[[ 25.16048721 -23.89648434]\n",
      " [ -8.79143026   9.93907682]]\n",
      "[[ 24.58628668 -23.32228381]\n",
      " [-10.33985882  11.48750538]]\n",
      "[[ 23.87001812 -22.60601525]\n",
      " [-12.16676531  13.31441186]]\n",
      "[[ 22.91100316 -21.64700029]\n",
      " [-14.50800401  15.65565057]]\n",
      "[[ 21.36765551 -20.10365263]\n",
      " [-18.28620923  19.43385579]]\n",
      "[[ 20.97635216 -19.71234929]\n",
      " [-36.7973816   37.94502816]]\n",
      "[[ 22.56087819 -21.29687532]\n",
      " [-35.53955888  36.68720544]]\n",
      "[[ 24.4848755  -23.22087263]\n",
      " [-33.97842596  35.12607252]]\n",
      "[[ 27.13498847 -25.8709856 ]\n",
      " [-31.83589311  32.98353967]]\n",
      "[[ 33.17930921 -31.91530634]\n",
      " [-27.70025374  28.8479003 ]]\n",
      "[[ 27.7222851  -26.45828223]\n",
      " [-42.33833659  43.48598315]]\n",
      "[[ 29.77157118 -28.50756831]\n",
      " [-40.61672194  41.7643685 ]]\n",
      "[[ 32.54174731 -31.27774444]\n",
      " [-38.29138632  39.43903287]]\n",
      "[[ 38.17563721 -36.91163434]\n",
      " [-34.10442398  35.25207054]]\n",
      "[[  88.30430384  -87.04030097]\n",
      " [ 114.75142131 -113.60377475]]\n",
      "[[  88.54107817  -87.2770753 ]\n",
      " [ 114.50704801 -113.35940145]]\n",
      "[[  88.77693379  -87.51293092]\n",
      " [ 114.26151121 -113.11386466]]\n",
      "[[  89.01187077  -87.7478679 ]\n",
      " [ 114.0148108  -112.86716424]]\n",
      "[[  89.24588915  -87.98188628]\n",
      " [ 113.76694662 -112.61930006]]\n",
      "[[  89.47898891  -88.21498604]\n",
      " [ 113.51791849 -112.37027193]]\n",
      "[[  89.71117005  -88.44716718]\n",
      " [ 113.26772618 -112.12007962]]\n",
      "[[  89.9424325   -88.67842963]\n",
      " [ 113.01636944 -111.86872288]]\n",
      "[[  90.17277618  -88.90877331]\n",
      " [ 112.76384796 -111.6162014 ]]\n",
      "[[  90.40220099  -89.13819811]\n",
      " [ 112.51016141 -111.36251485]]\n",
      "[[  90.63070677  -89.3667039 ]\n",
      " [ 112.25530942 -111.10766287]]\n",
      "[[  90.85829337  -89.5942905 ]\n",
      " [ 111.99929159 -110.85164503]]\n",
      "[[  91.08496059  -89.82095772]\n",
      " [ 111.74210746 -110.59446091]]\n",
      "[[  91.31070821  -90.04670534]\n",
      " [ 111.48375656 -110.33611   ]]\n",
      "[[  91.53553596  -90.27153309]\n",
      " [ 111.22423837 -110.07659181]]\n",
      "[[  91.75944357  -90.4954407 ]\n",
      " [ 110.96355233 -109.81590577]]\n",
      "[[  91.98243072  -90.71842785]\n",
      " [ 110.70169784 -109.55405128]]\n",
      "[[  92.20449707  -90.9404942 ]\n",
      " [ 110.43867427 -109.29102771]]\n",
      "[[  92.42564226  -91.16163939]\n",
      " [ 110.17448097 -109.02683441]]\n",
      "[[  92.64586589  -91.38186302]\n",
      " [ 109.90911721 -108.76147065]]\n",
      "[[  92.86516752  -91.60116465]\n",
      " [ 109.64258225 -108.49493569]]\n",
      "[[  93.0835467   -91.81954383]\n",
      " [ 109.37487532 -108.22722877]]\n",
      "[[  93.30100295  -92.03700008]\n",
      " [ 109.1059956  -107.95834904]]\n",
      "[[  93.51753575  -92.25353288]\n",
      " [ 108.83594222 -107.68829566]]\n",
      "[[  93.73314455  -92.46914168]\n",
      " [ 108.56471428 -107.41706773]]\n",
      "[[  93.94782878  -92.68382591]\n",
      " [ 108.29231087 -107.14466431]]\n",
      "[[  94.16158784  -92.89758497]\n",
      " [ 108.01873099 -106.87108443]]\n",
      "[[  94.37442109  -93.11041822]\n",
      " [ 107.74397364 -106.59632708]]\n",
      "[[  94.58632787  -93.322325  ]\n",
      " [ 107.46803777 -106.32039121]]\n",
      "[[  94.79730749  -93.53330462]\n",
      " [ 107.19092229 -106.04327573]]\n",
      "[[  95.00735922  -93.74335634]\n",
      " [ 106.91262607 -105.76497951]]\n",
      "[[  95.2164823   -93.95247943]\n",
      " [ 106.63314793 -105.48550138]]\n",
      "[[  95.42467596  -94.16067309]\n",
      " [ 106.35248669 -105.20484013]]\n",
      "[[  95.63193938  -94.36793651]\n",
      " [ 106.07064107 -104.92299451]]\n",
      "[[  95.83827171  -94.57426884]\n",
      " [ 105.78760981 -104.63996325]]\n",
      "[[  96.04367209  -94.77966922]\n",
      " [ 105.50339156 -104.35574501]]\n",
      "[[  96.24813959  -94.98413672]\n",
      " [ 105.21798497 -104.07033841]]\n",
      "[[  96.45167329  -95.18767042]\n",
      " [ 104.93138862 -103.78374207]]\n",
      "[[  96.65427222  -95.39026935]\n",
      " [ 104.64360107 -103.49595451]]\n",
      "[[  96.85593537  -95.5919325 ]\n",
      " [ 104.35462082 -103.20697426]]\n",
      "[[  97.05666171  -95.79265884]\n",
      " [ 104.06444634 -102.91679978]]\n",
      "[[  97.25645019  -95.99244732]\n",
      " [ 103.77307606 -102.6254295 ]]\n",
      "[[  97.4552997   -96.19129682]\n",
      " [ 103.48050837 -102.33286181]]\n",
      "[[  97.65320911  -96.38920624]\n",
      " [ 103.1867416  -102.03909504]]\n",
      "[[  97.85017728  -96.58617441]\n",
      " [ 102.89177405 -101.7441275 ]]\n",
      "[[  98.046203    -96.78220013]\n",
      " [ 102.595604   -101.44795744]]\n",
      "[[  98.24128505  -96.97728218]\n",
      " [ 102.29822964 -101.15058308]]\n",
      "[[  98.43542218  -97.17141931]\n",
      " [ 101.99964915 -100.85200259]]\n",
      "[[  98.62861309  -97.36461022]\n",
      " [ 101.69986066 -100.55221411]]\n",
      "[[  98.82085645  -97.55685358]\n",
      " [ 101.39886226 -100.2512157 ]]\n",
      "[[  99.01215092  -97.74814805]\n",
      " [ 101.09665198  -99.94900542]]\n",
      "[[  99.2024951   -97.93849223]\n",
      " [ 100.79322782  -99.64558127]]\n",
      "[[  99.39188756  -98.12788469]\n",
      " [ 100.48858774  -99.34094118]]\n",
      "[[  99.58032685  -98.31632398]\n",
      " [ 100.18272963  -99.03508307]]\n",
      "[[ 99.76781147 -98.5038086 ]\n",
      " [ 99.87565135 -98.72800479]]\n",
      "[[ 99.95433989 -98.69033702]\n",
      " [ 99.56735073 -98.41970417]]\n",
      "[[ 100.13991054  -98.87590767]\n",
      " [  99.25782553  -98.11017897]]\n",
      "[[ 100.32452184  -99.06051897]\n",
      " [  98.94707347  -97.79942691]]\n",
      "[[ 100.50817214  -99.24416927]\n",
      " [  98.63509222  -97.48744566]]\n",
      "[[ 100.69085976  -99.42685689]\n",
      " [  98.32187942  -97.17423286]]\n",
      "[[ 100.87258302  -99.60858015]\n",
      " [  98.00743264  -96.85978608]]\n",
      "[[ 101.05334015  -99.78933728]\n",
      " [  97.69174941  -96.54410285]]\n",
      "[[ 101.23312939  -99.96912652]\n",
      " [  97.37482721  -96.22718066]]\n",
      "[[ 101.4119489  -100.14794603]\n",
      " [  97.05666349  -95.90901693]]\n",
      "[[ 101.58979685 -100.32579398]\n",
      " [  96.73725561  -95.58960905]]\n",
      "[[ 101.76667133 -100.50266846]\n",
      " [  96.41660092  -95.26895436]]\n",
      "[[ 101.94257041 -100.67856754]\n",
      " [  96.09469669  -94.94705013]]\n",
      "[[ 102.11749213 -100.85348926]\n",
      " [  95.77154016  -94.6238936 ]]\n",
      "[[ 102.29143447 -101.0274316 ]\n",
      " [  95.44712851  -94.29948195]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "print(X)\n",
    "labels = labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "print(labels)\n",
    "\n",
    "for i in range(0,100):\n",
    "    q = softmax(X,W,b)\n",
    "    dscores = q\n",
    "    for column in range(0,4):\n",
    "        if labels[column] == 0:\n",
    "            dscores[0,column] -= 1\n",
    "        else:\n",
    "            dscores[1,column] -= 1\n",
    "    dscores = dscores / 4\n",
    "    dW = np.dot(X, dscores.T)\n",
    "    db = np.sum(dscores, axis = 1)\n",
    "    db = db.reshape(1, db.shape[0])\n",
    "    db = np.transpose(db)\n",
    "    W += -0.5*dW\n",
    "    b += -0.5*db\n",
    "    print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68258092 -1.41857805]\n",
      " [-2.58767111  3.73531767]]\n"
     ]
    }
   ],
   "source": [
    "dW = np.dot(X, dscores.T)\n",
    "W  += -0.5*dW\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5489428  -0.5184794   0.5195564   0.53756117]\n",
      " [ 0.5489428   0.5184794  -0.5195564  -0.53756117]]\n",
      "[-0.01030464  0.01030464]\n"
     ]
    }
   ],
   "source": [
    "print(dscores)\n",
    "db = np.sum(dscores, axis = 1)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 1 0]\n",
      " [0 1 3 4]]\n",
      "[ 0.  0.  1.  1.]\n",
      "confidences: [[ 0.4986421   0.4971809   0.49697428  0.49687097]\n",
      " [ 0.5013579   0.5028191   0.50302572  0.50312903]]\n",
      "dscores before loop [[ 0.4986421   0.5013579 ]\n",
      " [ 0.4971809   0.5028191 ]\n",
      " [ 0.49697428  0.50302572]\n",
      " [ 0.49687097  0.50312903]]\n",
      "dscores after loop [[-0.12533948  0.12533948]\n",
      " [-0.12570477  0.12570477]\n",
      " [ 0.12424357 -0.12424357]\n",
      " [ 0.12421774 -0.12421774]]\n",
      "confidences: [[ 0.73189403  0.68093332  0.14961103  0.04808458]\n",
      " [ 0.26810597  0.31906668  0.85038897  0.95191542]]\n",
      "dscores before loop [[ 0.73189403  0.26810597]\n",
      " [ 0.68093332  0.31906668]\n",
      " [ 0.14961103  0.85038897]\n",
      " [ 0.04808458  0.95191542]]\n",
      "dscores after loop [[-0.06702649  0.06702649]\n",
      " [-0.07976667  0.07976667]\n",
      " [ 0.03740276 -0.03740276]\n",
      " [ 0.01202114 -0.01202114]]\n",
      "confidences: [[ 0.85483313  0.85599054  0.17580322  0.03883754]\n",
      " [ 0.14516687  0.14400946  0.82419678  0.96116246]]\n",
      "dscores before loop [[ 0.85483313  0.14516687]\n",
      " [ 0.85599054  0.14400946]\n",
      " [ 0.17580322  0.82419678]\n",
      " [ 0.03883754  0.96116246]]\n",
      "dscores after loop [[-0.03629172  0.03629172]\n",
      " [-0.03600237  0.03600237]\n",
      " [ 0.04395081 -0.04395081]\n",
      " [ 0.00970939 -0.00970939]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "print(X)\n",
    "X = np.transpose(X)\n",
    "labels = labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "print(labels)\n",
    "\n",
    "#Train a Linear Classifier\n",
    "\n",
    "# initialize parameters randomly\n",
    "W = 0.01 * np.random.randn(2,2)\n",
    "b = np.zeros((1,2))\n",
    "\n",
    "# some hyperparameters\n",
    "h = 0.5\n",
    "\n",
    "# gradient descent loop\n",
    "m = X.shape[0]\n",
    "for i in range(3):\n",
    "    scores = np.dot(X, W) + b \n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "    print('confidences:', probs.T)\n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    correct_logprobs = -np.log(probs)\n",
    "    loss = np.sum(correct_logprobs)/m\n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    for column in range(0,4):\n",
    "        if labels[column] == 0:\n",
    "            dscores[column,0] -= 1\n",
    "        else:\n",
    "            dscores[column,1] -= 1\n",
    "    dscores /= m\n",
    "    # backpropate the gradient to the parameters (W,b)\n",
    "    dW = np.dot(X.T, dscores)\n",
    "    db = np.sum(dscores, axis=0, keepdims=True)\n",
    "    dW += reg*W # regularization gradient\n",
    "    # perform a parameter update\n",
    "    W += -h * dW\n",
    "    b += -h * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
