{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 21 (Dritte Aufgabe auf dem Blatt) - Lineare Klassifikation mit Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indikator(i,j):\n",
    "    if i == j:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X, W, b):\n",
    "    '''Gives back a matrix. q[i,j] is the confidence that point X[i] belongs to the j-th class.'''\n",
    "    scores = np.matmul(W, X) + b # quasi eine f-Matrix\n",
    "    nenner = scores.sum(axis=0) # Summiere bitte entlang der Spalten\n",
    "    q = scores/nenner\n",
    "    return q\n",
    "\n",
    "\n",
    "def getPredictions(q):\n",
    "    '''Returns the predicted labels with q from softmax'''\n",
    "    return np.argmax(q,axis=0)\n",
    "\n",
    "def learn(X, W, b, h, epochs):\n",
    "    m = X.shape[0] # amount of data points\n",
    "    for i in range(0,epochs):\n",
    "        q = softmax(X, W, b)\n",
    "        predictions = getPredictions(q)\n",
    "        diff = labels - predictions # the error in predicting the labels\n",
    "        summeFuer0 = np.zeros(2)\n",
    "        summeFuer1 = np.zeros(2)\n",
    "        for i in range(0, X.shape[1]):\n",
    "            if labels[i] == 0 and predictions[i] == 1:\n",
    "                summeFuer0 += X[:,i]\n",
    "                summeFuer1 -= X[:,i]\n",
    "            elif labels[i] == 1 and predictions[i] == 0:\n",
    "                summeFuer0 -= X[:,i]\n",
    "                summeFuer1 += X[:,i]\n",
    "        W[0] = W[0] - h/m * summeFuer0\n",
    "        W[1] = W[1] - h/m * summeFuer0\n",
    "        b = b - h/m * sum(diff)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5488135   0.71518937]\n",
      " [ 0.60276338  0.54488318]]\n",
      "[[ 0.4236548 ]\n",
      " [ 0.64589411]]\n"
     ]
    }
   ],
   "source": [
    "df_P_0 = pd.read_hdf('populationen.hdf5', key = 'P_0')\n",
    "P_0 = df_P_0.values\n",
    "df_P_1 = pd.read_hdf('populationen.hdf5', key = 'P_1')\n",
    "P_1 = df_P_1.values\n",
    "P = np.concatenate((P_0,P_1))\n",
    "P = np.transpose(P)\n",
    "labels = np.concatenate((np.zeros(P_0.shape[0]),np.ones(P_1.shape[0])))\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.rand(2,2)\n",
    "b = np.random.rand(2,1)\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 1 0]\n",
      " [0 1 3 4]]\n",
      "[ 0.  0.  1.  1.]\n",
      "[[ 0.81553443  0.44846844]\n",
      " [ 0.20395907  0.94368749]]\n",
      "[[ 0.99805581  0.26594706]\n",
      " [-0.06811434  1.2157609 ]]\n",
      "[[ 1.11485039  0.14915248]\n",
      " [-0.26478938  1.41243594]]\n",
      "[[ 1.18088167  0.0831212 ]\n",
      " [-0.41544086  1.56308742]]\n",
      "[[ 1.20609363  0.05790924]\n",
      " [-0.53947579  1.68712235]]\n",
      "[[ 1.19552179  0.06848108]\n",
      " [-0.65071424  1.7983608 ]]\n",
      "[[ 1.14906289  0.11493998]\n",
      " [-0.75969485  1.90734141]]\n",
      "[[ 1.05946364  0.20453923]\n",
      " [-0.87520569  2.02285225]]\n",
      "[[ 0.90373928  0.36026359]\n",
      " [-1.00564836  2.15329492]]\n",
      "[[ 0.58979576  0.67420712]\n",
      " [-1.16111127  2.30875782]]\n",
      "[[ 4.48410238 -3.22009951]\n",
      " [-1.36037993  2.50802649]]\n",
      "[[ 4.48240218 -3.21839931]\n",
      " [-3.88907266  5.03671922]]\n",
      "[[ 3.14542781 -1.88142494]\n",
      " [-3.15270098  4.30034754]]\n",
      "[[ 1.22215442  0.04184845]\n",
      " [-2.93577816  4.08342472]]\n",
      "[[-23.60835376  24.87235663]\n",
      " [-11.42438504  12.5720316 ]]\n",
      "[[-23.55752187  24.82152474]\n",
      " [-11.90839019  13.05603675]]\n",
      "[[-23.49917118  24.76317405]\n",
      " [-12.38348774  13.5311343 ]]\n",
      "[[-23.43355287  24.69755574]\n",
      " [-12.84996661  13.99761317]]\n",
      "[[-23.36089732  24.62490019]\n",
      " [-13.30809278  14.45573934]]\n",
      "[[-23.28141618  24.54541905]\n",
      " [-13.75811156  14.90575811]]\n",
      "[[-23.19530424  24.45930711]\n",
      " [-14.20024957  15.34789613]]\n",
      "[[-23.10274104  24.36674391]\n",
      " [-14.63471648  15.78236304]]\n",
      "[[-23.00389228  24.26789515]\n",
      " [-15.0617065   16.20935306]]\n",
      "[[-22.89891102  24.16291389]\n",
      " [-15.48139973  16.62904629]]\n",
      "[[-22.78793878  24.05194165]\n",
      " [-15.89396332  17.04160988]]\n",
      "[[-22.67110647  23.93510935]\n",
      " [-16.29955255  17.44719911]]\n",
      "[[-22.54853531  23.81253818]\n",
      " [-16.69831172  17.84595828]]\n",
      "[[-22.42033746  23.68434033]\n",
      " [-17.09037501  18.23802156]]\n",
      "[[-22.28661681  23.55061968]\n",
      " [-17.47586716  18.62351372]]\n",
      "[[-22.14746947  23.41147234]\n",
      " [-17.85490421  19.00255077]]\n",
      "[[-22.00298437  23.26698724]\n",
      " [-18.22759402  19.37524058]]\n",
      "[[-21.85324371  23.11724658]\n",
      " [-18.59403683  19.74168339]]\n",
      "[[-21.69832337  22.96232624]\n",
      " [-18.95432573  20.10197229]]\n",
      "[[-21.53829331  22.80229618]\n",
      " [-19.30854709  20.45619365]]\n",
      "[[-21.37321791  22.63722078]\n",
      " [-19.65678095  20.8044275 ]]\n",
      "[[-21.20315625  22.46715912]\n",
      " [-19.99910133  21.14674789]]\n",
      "[[-21.02816242  22.29216529]\n",
      " [-20.3355766   21.48322316]]\n",
      "[[-20.84828573  22.1122886 ]\n",
      " [-20.66626971  21.81391627]]\n",
      "[[-20.66357095  21.92757382]\n",
      " [-20.99123847  22.13888503]]\n",
      "[[-20.4740585   21.73806137]\n",
      " [-21.31053576  22.45818232]]\n",
      "[[-20.27978461  21.54378748]\n",
      " [-21.62420973  22.77185629]]\n",
      "[[-20.08078149  21.34478436]\n",
      " [-21.93230401  23.07995057]]\n",
      "[[-19.87707748  21.14108035]\n",
      " [-22.23485781  23.38250437]]\n",
      "[[-19.6686971   20.93269997]\n",
      " [-22.53190615  23.67955271]]\n",
      "[[-19.45566124  20.71966411]\n",
      " [-22.82347988  23.97112644]]\n",
      "[[-19.23798717  20.50199004]\n",
      " [-23.10960587  24.25725243]]\n",
      "[[-19.01568868  20.27969155]\n",
      " [-23.39030708  24.53795364]]\n",
      "[[-18.78877608  20.05277895]\n",
      " [-23.66560261  24.81324917]]\n",
      "[[-18.55725627  19.82125914]\n",
      " [-23.93550779  25.08315435]]\n",
      "[[-18.3211328   19.58513567]\n",
      " [-24.20003422  25.34768078]]\n",
      "[[-18.08040583  19.3444087 ]\n",
      " [-24.45918983  25.60683639]]\n",
      "[[-17.8350722   19.09907507]\n",
      " [-24.71297887  25.86062543]]\n",
      "[[-17.58512539  18.84912826]\n",
      " [-24.96140195  26.1090485 ]]\n",
      "[[-17.33055551  18.59455838]\n",
      " [-25.20445599  26.35210255]]\n",
      "[[-17.0713493   18.33535217]\n",
      " [-25.44213431  26.58978086]]\n",
      "[[-16.80749003  18.0714929 ]\n",
      " [-25.67442647  26.82207303]]\n",
      "[[-16.53895753  17.8029604 ]\n",
      " [-25.90131834  27.0489649 ]]\n",
      "[[-16.26572805  17.52973092]\n",
      " [-26.12279201  27.27043857]]\n",
      "[[-15.98777423  17.2517771 ]\n",
      " [-26.33882571  27.48647227]]\n",
      "[[-15.705065    16.96906787]\n",
      " [-26.54939373  27.69704029]]\n",
      "[[-15.41756543  16.6815683 ]\n",
      " [-26.75446638  27.90211293]]\n",
      "[[-15.12523668  16.38923955]\n",
      " [-26.9540098   28.10165635]]\n",
      "[[-14.8280358   16.09203867]\n",
      " [-27.14798589  28.29563245]]\n",
      "[[-14.5259156   15.78991848]\n",
      " [-27.33635218  28.48399874]]\n",
      "[[-14.21882448  15.48282735]\n",
      " [-27.51906158  28.66670814]]\n",
      "[[-13.90670619  15.17070906]\n",
      " [-27.69606232  28.84370888]]\n",
      "[[-13.58949966  14.85350253]\n",
      " [-27.86729763  29.01494419]]\n",
      "[[-13.26713874  14.53114161]\n",
      " [-28.0327056   29.18035216]]\n",
      "[[-12.93955188  14.20355475]\n",
      " [-28.19221886  29.33986542]]\n",
      "[[-12.60666191  13.87066479]\n",
      " [-28.34576436  29.49341092]]\n",
      "[[-12.26838563  13.5323885 ]\n",
      " [-28.49326298  29.64090954]]\n",
      "[[-11.92463347  13.18863634]\n",
      " [-28.63462925  29.78227581]]\n",
      "[[-11.57530904  12.83931191]\n",
      " [-28.76977092  29.91741748]]\n",
      "[[-11.22030873  12.4843116 ]\n",
      " [-28.89858853  30.04623509]]\n",
      "[[-10.85952112  12.12352399]\n",
      " [-29.02097494  30.1686215 ]]\n",
      "[[-10.49282646  11.75682933]\n",
      " [-29.13681481  30.28446137]]\n",
      "[[-10.12009599  11.38409886]\n",
      " [-29.24598395  30.39363051]]\n",
      "[[ -9.74119125  11.00519412]\n",
      " [-29.34834871  30.49599527]]\n",
      "[[ -9.35596327  10.61996614]\n",
      " [-29.44376519  30.59141175]]\n",
      "[[ -8.96425163  10.22825451]\n",
      " [-29.53207842  30.67972498]]\n",
      "[[ -8.56588353   9.8298864 ]\n",
      " [-29.61312146  30.76076802]]\n",
      "[[ -8.16067252   9.42467539]\n",
      " [-29.68671426  30.83436082]]\n",
      "[[ -7.74841734   9.01242021]\n",
      " [-29.75266253  30.90030909]]\n",
      "[[ -7.32890033   8.5929032 ]\n",
      " [-29.81075639  30.95840295]]\n",
      "[[ -6.90188582   8.16588869]\n",
      " [-29.8607688   31.00841536]]\n",
      "[[ -6.46711821   7.73112108]\n",
      " [-29.90245383  31.05010039]]\n",
      "[[ -6.02431972   7.28832259]\n",
      " [-29.93554467  31.08319123]]\n",
      "[[ -5.57318793   6.8371908 ]\n",
      " [-29.95975135  31.1073979 ]]\n",
      "[[ -5.1133928    6.37739567]\n",
      " [-29.97475805  31.12240461]]\n",
      "[[ -4.64457329   5.90857616]\n",
      " [-29.98022011  31.12786667]]\n",
      "[[ -4.16633336   5.43033623]\n",
      " [-29.97576041  31.12340697]]\n",
      "[[ -3.67823734   4.94224021]\n",
      " [-29.96096526  31.10861182]]\n",
      "[[ -3.17980435   4.44380722]\n",
      " [-29.93537948  31.08302604]]\n",
      "[[ -2.67050179   3.93450466]\n",
      " [-29.89850061  31.04614717]]\n",
      "[[ -2.14973748   3.41374035]\n",
      " [-29.84977208  30.99741864]]\n",
      "[[ -1.61685015   2.88085302]\n",
      " [-29.78857487  30.93622143]]\n",
      "[[ -1.07109799   2.33510086]\n",
      " [-29.71421761  30.86186417]]\n",
      "[[ -0.51164447   1.77564734]\n",
      " [-29.62592438  30.77357094]]\n",
      "[[  0.06245912   1.20154375]\n",
      " [-29.5228198   30.67046636]]\n",
      "[[  0.65229551   0.61170736]\n",
      " [-29.40391044  30.55155699]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "print(X)\n",
    "labels = labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "print(labels)\n",
    "\n",
    "for i in range(0,100):\n",
    "    q = softmax(X,W,b)\n",
    "    dscores = q\n",
    "    for column in range(0,4):\n",
    "        if labels[column] == 0:\n",
    "            dscores[0,column] -= 1\n",
    "        else:\n",
    "            dscores[1,column] -= 1\n",
    "    dscores = dscores / 4\n",
    "    dW = np.dot(X, dscores.T)\n",
    "    db = np.sum(dscores, axis = 1)\n",
    "    db = db.reshape(1, db.shape[0])\n",
    "    db = np.transpose(db)\n",
    "    W += -0.5*dW\n",
    "    b += -0.5*db\n",
    "    print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.24213191e+00   2.18709638e-02]\n",
      " [ -2.92850011e+01   3.04326476e+01]]\n"
     ]
    }
   ],
   "source": [
    "dW = np.dot(X, dscores.T)\n",
    "W  += -0.5*dW\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23261003 -0.23755348 -0.00179229  0.0012779 ]\n",
      " [ 0.23261003  0.23755348  0.00179229 -0.0012779 ]]\n",
      "[-0.47067789  0.47067789]\n"
     ]
    }
   ],
   "source": [
    "print(dscores)\n",
    "db = np.sum(dscores, axis = 1)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 1 0]\n",
      " [0 1 3 4]]\n",
      "[ 0.  0.  1.  1.]\n",
      "confidences: [[ 0.50550701  0.50697585  0.49889999  0.49486201]\n",
      " [ 0.49449299  0.49302415  0.50110001  0.50513799]]\n",
      "confidences: [[ 0.73204755  0.68079287  0.14791956  0.04719027]\n",
      " [ 0.26795245  0.31920713  0.85208044  0.95280973]]\n",
      "confidences: [[ 0.85512154  0.85642728  0.17498404  0.03845599]\n",
      " [ 0.14487846  0.14357272  0.82501596  0.96154401]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "print(X)\n",
    "X = np.transpose(X)\n",
    "labels = labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "print(labels)\n",
    "\n",
    "#Train a Linear Classifier\n",
    "\n",
    "# initialize parameters randomly\n",
    "W = 0.01 * np.random.randn(2,2)\n",
    "b = np.zeros((1,2))\n",
    "\n",
    "# some hyperparameters\n",
    "h = 0.5\n",
    "\n",
    "# gradient descent loop\n",
    "m = X.shape[0]\n",
    "for i in range(3):\n",
    "    scores = np.dot(X, W) + b \n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "    print('confidences:', probs.T)\n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    correct_logprobs = -np.log(probs)\n",
    "    loss = np.sum(correct_logprobs)/m\n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    for column in range(0,4):\n",
    "        if labels[column] == 0:\n",
    "            dscores[column,0] -= 1\n",
    "        else:\n",
    "            dscores[column,1] -= 1\n",
    "    dscores /= m\n",
    "    # backpropate the gradient to the parameters (W,b)\n",
    "    dW = np.dot(X.T, dscores)\n",
    "    db = np.sum(dscores, axis=0, keepdims=True)\n",
    "    dW += reg*W # regularization gradient\n",
    "    # perform a parameter update\n",
    "    W += -h * dW\n",
    "    b += -h * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class net:    \n",
    "    def __init__(self):\n",
    "        np.random.seed(0)\n",
    "        self.W = np.random.randn(2,2)\n",
    "        self.b = np.zeros((2,1))   \n",
    "        \n",
    "    def train(self, X, stepsize, epochs):\n",
    "        m = X.shape[0]\n",
    "        for i in range(epochs):\n",
    "            scores = np.dot(self.W, X) + self.b \n",
    "            exp_scores = np.exp(scores)\n",
    "            probs = exp_scores / np.sum(exp_scores, axis=0, keepdims=True) # [N x K]\n",
    "            if i%10 == 0: print(probs)\n",
    "            # compute the loss: average cross-entropy loss and regularization\n",
    "            correct_logprobs = -np.log(probs)\n",
    "            loss = np.sum(correct_logprobs)/m\n",
    "            # compute the gradient on scores\n",
    "            dscores = probs\n",
    "            for column in range(0,m):\n",
    "                if labels[column] == 0:\n",
    "                    dscores[0,column] -= 1\n",
    "                else:\n",
    "                    dscores[1,column] -= 1\n",
    "            dscores /= m\n",
    "            #print(X)\n",
    "            #print('dscores', dscores)\n",
    "            # backpropate the gradient to the parameters (W,b)\n",
    "            dW = np.dot(dscores, X.T)\n",
    "            #dW = np.transpose(dW)\n",
    "            #print('dW', dW)\n",
    "            db = np.sum(dscores, axis=1, keepdims=True)\n",
    "            # perform a parameter update\n",
    "            self.W += -h * dW\n",
    "            self.b += -h * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.27873219e-01   6.26026344e-01   8.68966190e-03   6.33926152e-04]\n",
      " [  1.72126781e-01   3.73973656e-01   9.91310338e-01   9.99366074e-01]]\n",
      "[[ 0.97147847  0.97995979  0.17381565  0.01361171]\n",
      " [ 0.02852153  0.02004021  0.82618435  0.98638829]]\n",
      "[[ 0.97254071  0.98041781  0.17477876  0.01358816]\n",
      " [ 0.02745929  0.01958219  0.82522124  0.98641184]]\n",
      "[[ 0.97306976  0.98037453  0.17466936  0.013588  ]\n",
      " [ 0.02693024  0.01962547  0.82533064  0.986412  ]]\n",
      "[[ 0.97346635  0.98021216  0.17430332  0.01359324]\n",
      " [ 0.02653365  0.01978784  0.82569668  0.98640676]]\n",
      "[[ 0.9738252   0.9800223   0.17388318  0.01359979]\n",
      " [ 0.0261748   0.0199777   0.82611682  0.98640021]]\n",
      "[[ 0.97416952  0.97982776  0.1734589   0.01360663]\n",
      " [ 0.02583048  0.02017224  0.8265411   0.98639337]]\n",
      "[[ 0.97450517  0.97963426  0.1730426   0.01361351]\n",
      " [ 0.02549483  0.02036574  0.8269574   0.98638649]]\n",
      "[[ 0.97483369  0.97944325  0.17263699  0.01362035]\n",
      " [ 0.02516631  0.02055675  0.82736301  0.98637965]]\n",
      "[[ 0.97515561  0.97925505  0.17224242  0.01362714]\n",
      " [ 0.02484439  0.02074495  0.82775758  0.98637286]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2,3,1,0],[0,1,3,4]])\n",
    "labels = labels = np.concatenate((np.zeros(2),np.ones(2)))\n",
    "\n",
    "testnet = net()\n",
    "testnet.train(X, stepsize = 0.05, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
