{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 - k-NN Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist # Vektorisierte Funktion,\n",
    "#um schnell den Abstand zwischen einer Menge an Punkten zu bestimmen und in einer Matrix zu speichern\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    '''KNN Classifier.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of neighbors to consider.\n",
    "    '''\n",
    "    def __init__(self, k):\n",
    "        '''Initialization.\n",
    "        Parameters are stored as member variables/attributes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of neighbors to consider.\n",
    "        '''\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Fit routine.\n",
    "        Training data is stored within object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Training data.\n",
    "        y : numpy.array shape=(n_samples)\n",
    "            Training labels.\n",
    "        '''\n",
    "        self.training_data = X\n",
    "        self.training_labels = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Prediction routine.\n",
    "        Predict class association of each sample of X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Data to classify.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        prediction : numpy.array, shape=(n_samples)\n",
    "            Predictions, containing the predicted label of each sample.\n",
    "        '''\n",
    "        \n",
    "        # First we need to find a few parameters\n",
    "        n_attributes, n_samples = X.shape\n",
    "        n_training_data = np.size(self.training_data, axis = 1) # this means finding the amount of columns\n",
    "        \n",
    "        prediction = []\n",
    "        \n",
    "        for i in range(X.shape[0]): # für jeden zu klassifizierenden Datenpunkt\n",
    "            back = 0 # ein Counter für die Anzahl der nächsten Nachbarn, die Background-Ereignisse sind\n",
    "            sig = 0 # und nochmal für die Signal-nächsten-Nachbarn\n",
    "            a = X[i] # keine Veränderung von Arrays in For Loops in Python, deswegen ein temporäres Objekt\n",
    "            if len(a.shape) != 2: # mache eben aus a ein 2d-Array mit nur einer Zeile, falls es noch keins ist.\n",
    "                a = a.reshape(1, a.shape[0])\n",
    "            distanceTest = cdist(a, self.training_data)[0] # Hierfür MUESSEN beide Arrays zweidimensional sein\n",
    "            distanceList = np.stack((distanceTest, self.training_labels), axis=-1) # Klebe die beiden Arrays als Spalten zusammen!\n",
    "            sortedDistanceList = distanceList[distanceList[:,0].argsort()] # Sortiere nach der ersten Spalte!\n",
    "            kNearestNeighbors = sortedDistanceList[:self.k] # Nimm nur die ersten k Werte -> k nächste Nachbarn\n",
    "            for l in range(0, self.k):\n",
    "                if kNearestNeighbors[l,1] == 0:\n",
    "                    back += 1\n",
    "                else:\n",
    "                    sig +=1\n",
    "            if back > sig:\n",
    "                prediction.append(0)\n",
    "            elif back < sig:\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(float('NaN')) # Falls gleich viele Signale und Background in der Nachbarschaft liegen\n",
    "                # können wir keine Entscheidung treffen...\n",
    "        return np.asarray(prediction) # Gib ein numpy Array zurück, weil man damit besser arbeiten kann als mit einer Liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d)\n",
    "Der selbst geschriebene KNN-Klassifikator wird an dem NeutrinoMC-Beispiel getestet.\n",
    "Wir definieren zunächst einige Funktionen und analysieren die Daten. Die Ergebnisse sind zufriedenstellend, KNN kann die Daten recht gut zuordnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataFromFile(filename, key, log = False):\n",
    "    '''Gets the hits, x and y from a NeutrinoMC-file, cuts any nans and returns them as a numpy matrix\n",
    "    If getDataFromFile is invoked with log = True the decadic logarithm of the hits will be used.'''\n",
    "    hdf = pd.read_hdf(filename, key)\n",
    "    hits = hdf.NumberOfHits\n",
    "    x = hdf.x\n",
    "    y = hdf.y\n",
    "    hits = np.asarray(hits)\n",
    "    if log == True:\n",
    "        hits = np.log10(hits)\n",
    "    hits = hits[~np.isnan(hits)] # ~ means not \n",
    "    x = np.asarray(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y)\n",
    "    y = y[~np.isnan(y)]\n",
    "    return np.transpose(np.matrix([hits, x, y])) # Wir wollen die Attribute des Punktes x_i in der i-ten Zeile haben\n",
    "\n",
    "\n",
    "def getKNNData(matrixSignal, matrixBackground, lenTraining, lenSignal, lenBackground, shuffle = False, seed = 0):\n",
    "    '''Takes two Matrizes matrixSignal and matrixBackground. Returns three numpy arrays:\n",
    "    TrainingData contains 2*lenTraining points. TrainingData[0:lenTraining] is the background data used to train the knn classifier,\n",
    "    TrainingData[lenTraining:2lenTraining] is the signal data used to train.\n",
    "    TestDataSignal contains lenSignal signal points to test the model, TestDataBackground is analogous.\n",
    "    If getKNNData is invoked with shuffle = True the given data is shuffled randomly with a function from sklearn.'''\n",
    "    if shuffle == True:\n",
    "        matrixSignal, matrixBackground = shuffle(matrixSignal, matrixBackground, random_state=seed)\n",
    "    matrixSignal = matrixSignal[:lenTraining+lenSignal:,] # Nimm bitte die ersten lenTraining+lenSignal\n",
    "    matrixBackground = matrixBackground[:lenTraining+lenBackground:,]\n",
    "    \n",
    "    trainingDataBackground, testDataBackground = np.split(matrixBackground, [lenTraining])\n",
    "    trainingDataSignal, testDataSignal = np.split(matrixSignal, [lenTraining])\n",
    "    #trainingDataBackground, testDataBackground = train_test_split(matrixBackground, test_size = lenBackground, train_size = lenTraining, shuffle=False)\n",
    "    #trainingDataSignal, testDataSignal = train_test_split(matrixSignal, test_size = lenSignal, train_size = lenTraining, suffle=False)\n",
    "    trainingData = np.concatenate((trainingDataBackground, trainingDataSignal), axis=0)\n",
    "    \n",
    "    return trainingData, testDataBackground, testDataSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenTraining = 5000\n",
    "lenSignal = 10000\n",
    "lenBackground = 20000\n",
    "k = 10\n",
    "\n",
    "matrixSignal = getDataFromFile(filename='NeutrinoMC.hdf5', key='Signal')\n",
    "matrixBackground = getDataFromFile(filename='NeutrinoMC.hdf5', key='Background')\n",
    "trainingData, testDataBackground, testDataSignal = getKNNData(matrixSignal, matrixBackground,\n",
    "                                                              lenTraining, lenSignal, lenBackground)\n",
    "labels = np.concatenate((np.zeros(lenTraining),np.ones(lenTraining))) # 0 = Background, 1 = Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 26.           6.69494405   2.20707621]\n",
      " [ 38.           7.74364571   3.57920725]\n",
      " [ 87.           7.41714979   2.96454426]\n",
      " ..., \n",
      " [ 52.           7.71972272   3.19118159]\n",
      " [ 25.           7.64833004   3.48405199]\n",
      " [ 12.           7.779087     3.8578863 ]]\n",
      "[[ 26.           6.69494405   2.20707621]]\n",
      "(1, 3)\n",
      "[ 26.           6.69494405   2.20707621]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(matrixSignal)\n",
    "test = matrixSignal[0:1,]\n",
    "print(test)\n",
    "print(test.shape)\n",
    "print(np.ravel(test))\n",
    "print(np.ravel(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyData(k, trainingData, labels, testDataSignal, testDataBackground):\n",
    "    '''Analyzes a given Testset based on trainingdata and labels. Uses knn with k nearest neighbors.\n",
    "    Results (tp, fn, fp, tn, precision, recall and significance) are printed to screen.'''\n",
    "    knn = KNN(k)\n",
    "    knn.fit(trainingData, labels)\n",
    "    predictionS = knn.predict(testDataSignal)\n",
    "    predictionB = knn.predict(testDataBackground)\n",
    "    predictionS = np.asarray(predictionS)\n",
    "    predictionB = np.asarray(predictionB)\n",
    "    tp = np.count_nonzero(predictionS == 1) # Neutrinos, die korrekt als Neutrino zugeordnet werden\n",
    "    fn = np.count_nonzero(predictionS == 0) # Neutrinos, die fälschlicherweise als Background zugeordnet werden\n",
    "    fp = np.count_nonzero(predictionB == 1) # Background, der fälschlicherweise als Neutrino zugeordnet wird\n",
    "    tn = np.count_nonzero(predictionB == 0) # Background, der korrekt als Background zugeordnet wird\n",
    "    print('tp', tp)\n",
    "    print('fn', fn)\n",
    "    print('fp', fp)\n",
    "    print('tn', tn)\n",
    "    Reinheit = tp/(tp+fp)\n",
    "    Effizienz = tp/(tp+fn)\n",
    "    Signifikanz = tp/(np.sqrt(tp+fp))\n",
    "    print('Reinheit =', Reinheit)\n",
    "    print('Effizienz =', Effizienz)\n",
    "    print('Signifikanz =', Signifikanz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ff67058334b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifyData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestDataSignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestDataBackground\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-0c620b95ec33>\u001b[0m in \u001b[0;36mclassifyData\u001b[1;34m(k, trainingData, labels, testDataSignal, testDataBackground)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpredictionS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDataSignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredictionB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDataBackground\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mpredictionS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpredictionB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-eec588de5190>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# mache eben aus a ein 2d-Array mit nur einer Zeile, falls es noch keins ist.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mdistanceTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Hierfür MUESSEN beide Arrays zweidimensional sein\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mdistanceList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistanceTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Klebe die beiden Arrays als Spalten zusammen!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0msortedDistanceList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistanceList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistanceList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Sortiere nach der ersten Spalte!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jlspa\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, p, V, VI, w)\u001b[0m\n\u001b[0;32m   2204\u001b[0m             \u001b[0mXA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2205\u001b[0m             \u001b[0mXB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2206\u001b[1;33m             \u001b[0mcdist_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2207\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifyData(k, trainingData, labels, testDataSignal, testDataBackground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe e)\n",
    "Wir verwenden nun $\\mathrm{log}_{10}$(Hits) statt Hits. Das führt zu einer verbesserten Zuordnung der Daten, da alle Qualitätsmaße verbessert werden. Es wurden nur noch 1,2% statt 2,6% der Neutrinos fälschlicherweise dem Background zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixSignal = getDataFromFile(filename='NeutrinoMC.hdf5', key='Signal', log=True)\n",
    "matrixBackground = getDataFromFile(filename='NeutrinoMC.hdf5', key='Background', log=True)\n",
    "trainingData, testDataBackground, testDataSignal = getKNNData(matrixSignal, matrixBackground,\n",
    "                                                              lenTraining, lenSignal, lenBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyData(k, trainingData, labels, testDataSignal, testDataBackground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe f)\n",
    "Nun wird $k=20$ gewählt. Es ist zu erkennen, dass die Analyse ohne den Logarithmus streng schlechter ist.\n",
    "Mit dem Logarithmus ist es schwieriger: Es werden mehr Neutrinos korrekt zugeordnet als mit $k=10$, ober die Zuordnung der Background-Events im Testset wird schlechter. Dies resultiert in einer geringeren Reinheit, aber in einer leicht besseren Effizienz.<br>\n",
    "Man müsste weitere Werte für $k$ untersuchen, um genauere Schlüsse zu ziehen; jedoch kann man vermuten, dass in der Nähe von $k=20$ Underfitting vorliegt. Wenn zu viele nächste Nachbarn untersucht werden, wird die Analyse geglättet und unsensitiver für den Input (Beispiel: Wählt man zum Beispiel $k$ als Größe des Testsets wäre der Output konstant und unabhängig von den Attributwerten). Wie gesagt müsste man die Qualitätsmaße in Abhängigkeit von $k$ allerdings genauer untersuchen, um auch nur annäherend sichere Aussagen über die beste Wahl von $k$ zu treffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixSignal = getDataFromFile(filename='NeutrinoMC.hdf5', key='Signal')\n",
    "matrixBackground = getDataFromFile(filename='NeutrinoMC.hdf5', key='Background')\n",
    "trainingData, testDataBackground, testDataSignal = getKNNData(matrixSignal, matrixBackground,\n",
    "                                                              lenTraining, lenSignal, lenBackground)\n",
    "labels = np.concatenate((np.zeros(lenTraining),np.ones(lenTraining))) # 0 = Background, 1 = Signal\n",
    "classifyData(k, trainingData, labels, testDataSignal, testDataBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixSignal = getDataFromFile(filename='NeutrinoMC.hdf5', key='Signal', log=True)\n",
    "matrixBackground = getDataFromFile(filename='NeutrinoMC.hdf5', key='Background', log=True)\n",
    "trainingData, testDataBackground, testDataSignal = getKNNData(matrixSignal, matrixBackground,\n",
    "                                                              lenTraining, lenSignal, lenBackground)\n",
    "classifyData(k, trainingData, labels, testDataSignal, testDataBackground)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
