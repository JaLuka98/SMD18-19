{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 - k-NN Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist # Vektorisierte Funktion,\n",
    "#um schnell den Abstand zwischen einer Menge an Punkten zu bestimmen und in einer Matrix zu speichern\n",
    "from sklearn.model_selection import train_test_split # Um randomisierte Trainings- und Testsets zu erstellen\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    '''KNN Classifier.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of neighbors to consider.\n",
    "    '''\n",
    "    def __init__(self, k):\n",
    "        '''Initialization.\n",
    "        Parameters are stored as member variables/attributes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of neighbors to consider.\n",
    "        '''\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Fit routine.\n",
    "        Training data is stored within object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Training data.\n",
    "        y : numpy.array shape=(n_samples)\n",
    "            Training labels.\n",
    "        '''\n",
    "        self.training_data = X\n",
    "        self.training_labels = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Prediction routine.\n",
    "        Predict class association of each sample of X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Data to classify.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        prediction : numpy.array, shape=(n_samples)\n",
    "            Predictions, containing the predicted label of each sample.\n",
    "        '''\n",
    "        \n",
    "        # First we need to find a few parameters\n",
    "        n_attributes, n_samples = X.shape\n",
    "        n_training_data = np.size(self.training_data, axis = 1) # this means finding the amount of columns\n",
    "        \n",
    "        prediction = []\n",
    "        \n",
    "        for i in range(X.shape[0]): # für jeden zu klassifizierenden Datenpunkt\n",
    "            distanceList = []\n",
    "            kNearestNeighbors = []\n",
    "            back = 0\n",
    "            sig = 0\n",
    "            counter = 0\n",
    "            a = X[i]\n",
    "            if len(a.shape) != 2: # mache eben aus a ein 2d-Array mit nur einer Zeile, falls es noch keins ist.\n",
    "                a = a.reshape(1, a.shape[0])\n",
    "            distanceTest = cdist(a, self.training_data)[0] # Hierfür MUESSEN beide Arrays zweidimensional sein\n",
    "            distanceList = np.stack((distanceTest, self.training_labels), axis=-1) # Klebe die beiden Arrays als Spalten zusammen!\n",
    "            sortedDistanceList = distanceList[distanceList[:,0].argsort()] # Sortiere nach der ersten Spalte!\n",
    "            kNearestNeighbors = sortedDistanceList[:self.k] # Nimm nur die ersten k Werte -> k nächste Nachbarn\n",
    "            for l in range(0, self.k):\n",
    "                if kNearestNeighbors[l,1] == 0:\n",
    "                    back += 1\n",
    "                else:\n",
    "                    sig +=1\n",
    "            if back > sig:\n",
    "                prediction.append(0)\n",
    "            elif back < sig:\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(float('NaN'))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromFile(filename, key):\n",
    "    \"Gets the hits, x and y from a NeutrinoMC-file, cuts any nans and returns them as a numpy matrix\"\n",
    "    hdf = pd.read_hdf(filename, key)\n",
    "    hits = hdf.NumberOfHits\n",
    "    x = hdf.x\n",
    "    y = hdf.y\n",
    "    hits = np.asarray(hits)\n",
    "    hits = hits[~np.isnan(hits)] # ~ means not \n",
    "    x = np.asarray(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y)\n",
    "    y = y[~np.isnan(y)]\n",
    "    return np.transpose(np.matrix([hits, x, y])) # Wir wollen die Attribute des Punktes x_i in der i-ten Zeile haben\n",
    "\n",
    "\n",
    "def getKNNData(matrixSignal, matrixBackground, lenTraining, lenSignal, lenBackground):\n",
    "    '''Takes two Matrizes matrixSignal and matrixBackground. Returns three numpy arrays:\n",
    "    TrainingData contains 2*lenTraining points. TrainingData[0:lenTraining] is the background data used to train the knn classifier,\n",
    "    TrainingData[lenTraining:2lenTraining] is the signal data used to train.\n",
    "    TestDataSignal contains lenSignal signal points to test the model, TestDataBackground is analogous.'''\n",
    "    matrixSignal.shuffle() # Sicherstellen, dass die Daten gut gemischt sind (aus Bibliothek random)\n",
    "    matrixBackground.shuffle()\n",
    "    matrixSignal = matrixTraining[:lenTraining+lenSignal:,] # Nimm bitte die ersten lenTraining+lenSignal\n",
    "    matrixBackground = matrixTraining[:lenTraining+lenBackground:,]\n",
    "    \n",
    "    trainingDataBackground, testDataBackground = train_test_split(matrixBackground, test_size = lenBackground, train_size = lenTraining)\n",
    "    trainingDataSignal, testDataSignal = train_test_split(matrixSignal, test_size = lenSignal, train_size = lenTraining)\n",
    "    trainingData = np.concatenate((trainingDataBackground, trainingDataSignal), axis=1)\n",
    "    \n",
    "    return trainingData, testDataBackground, testDataSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 26.          38.          87.         ...,  52.          25.          12.        ]\n",
      " [  6.69494405   7.74364571   7.41714979 ...,   7.71972272   7.64833004\n",
      "    7.779087  ]\n",
      " [  2.20707621   3.57920725   2.96454426 ...,   3.19118159   3.48405199\n",
      "    3.8578863 ]]\n"
     ]
    }
   ],
   "source": [
    "lenTraining = 5000\n",
    "lenSignal = 10000\n",
    "lenBackground = 20000\n",
    "\n",
    "hdf = pd.read_hdf('NeutrinoMC.hdf5', key = 'Signal')\n",
    "hits = hdf.NumberOfHits\n",
    "x = hdf.x\n",
    "y = hdf.y\n",
    "\n",
    "hits = np.asarray(hits)\n",
    "hits = hits[~np.isnan(hits)] # ~ means not \n",
    "x = np.asarray(x)\n",
    "x = x[~np.isnan(x)]\n",
    "y = np.asarray(y)\n",
    "y = y[~np.isnan(y)]\n",
    "\n",
    "matrix = np.matrix([hits, x, y])\n",
    "#matrix = getDataFromFile(filename='NeutrinoMC.hdf5', key='Signal')\n",
    "print(matrix) # Looking at the matrix to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataSignal = matrix[:,0:lenTraining]\n",
    "testDataSignal = matrix[:,lenTraining:lenTraining+lenSignal]\n",
    "testDataSignal = np.transpose(testDataSignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pd.read_hdf('NeutrinoMC.hdf5', key = 'Background')\n",
    "hits = hdf.NumberOfHits\n",
    "x = hdf.x\n",
    "y = hdf.y\n",
    "\n",
    "hits = np.asarray(hits)\n",
    "hits = hits[~np.isnan(hits)]\n",
    "x = np.asarray(x)\n",
    "x = x[~np.isnan(x)]\n",
    "y = np.asarray(y)\n",
    "y = y[~np.isnan(y)]\n",
    "\n",
    "matrix = np.matrix([hits, x, y])\n",
    "trainingDataBackground = matrix[:,0:lenTraining]\n",
    "testDataBackground = matrix[:,lenTraining:lenBackground+lenTraining]\n",
    "testDataBackground = np.transpose(testDataBackground)\n",
    "\n",
    "\n",
    "trainingData = np.concatenate((trainingDataBackground, trainingDataSignal), axis=1)\n",
    "trainingData = np.transpose(trainingData)\n",
    "\n",
    "y1 = np.zeros(lenTraining)\n",
    "y2 = np.ones(lenTraining)\n",
    "labels = np.concatenate((y1,y2)) # 0 = Background, 1 = Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(10)\n",
    "knn.fit(trainingData, labels)\n",
    "predictionS = knn.predict(testDataSignal)\n",
    "predictionB = knn.predict(testDataBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp 9679\n",
      "fn 242\n",
      "fp 1824\n",
      "tn 17829\n",
      "Reinheit = 0.8414326697383291\n",
      "Effizienz = 0.9756072976514464\n",
      "Signifikanz = 90.2453700219\n"
     ]
    }
   ],
   "source": [
    "predictionS = np.asarray(predictionS)\n",
    "predictionB = np.asarray(predictionB)\n",
    "tp = np.count_nonzero(predictionS == 1)\n",
    "fn = np.count_nonzero(predictionS == 0)\n",
    "fp = np.count_nonzero(predictionB == 1)\n",
    "tn = np.count_nonzero(predictionB == 0)\n",
    "print('tp', tp)\n",
    "print('fn', fn)\n",
    "print('fp', fp)\n",
    "print('tn', tn)\n",
    "Reinheit = tp/(tp+fp)\n",
    "Effizienz = tp/(tp+fn)\n",
    "Signifikanz = tp/(np.sqrt(tp+fp))\n",
    "print('Reinheit =', Reinheit)\n",
    "print('Effizienz =', Effizienz)\n",
    "print('Signifikanz =', Signifikanz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.90000000e+01   6.40000000e+01   1.40000000e+01   2.02000000e+02\n",
      "   3.00000000e+00   7.30000000e+01   1.83000000e+02   9.90900000e+03\n",
      "   1.51000000e+02   8.79000000e+02   9.70000000e+01   1.33000000e+02\n",
      "   3.00000000e+01   1.08000000e+03   1.17000000e+02   1.86000000e+02\n",
      "   1.80000000e+01   5.00000000e+00   3.50000000e+01   1.85700000e+03]\n"
     ]
    }
   ],
   "source": [
    "hits = hdf.NumberOfHits\n",
    "hits = np.asarray(hits)\n",
    "hits = hits[~np.isnan(hits)]\n",
    "print(hits[0:20])\n",
    "hits = np.log10(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
